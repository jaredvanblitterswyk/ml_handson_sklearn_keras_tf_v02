{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "freelance-crime",
   "metadata": {},
   "source": [
    "# Predicting Housing Prices in California\n",
    "\n",
    "This notebook presents a framework for an end-to-end pipeline to implement ML on a basic data set of housing data with the objective to predict housing prices in California [1].\n",
    "\n",
    "<b>Add more description here as the project progresses.</b>\n",
    "\n",
    "---\n",
    "\n",
    "[1]: A. Geron, 'Hands-on Machine Learning with Scikit-Learn, Keras & TensorFolow, Ch. 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "horizontal-cruise",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "\n",
    "First setup a few modulues, set some defaults for matplotlib figures and setup a random seed so that the code runs the same each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "alternative-expansion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# setup matplotlib defaults\n",
    "mpl.rc('axes', labelsize = 10)\n",
    "mpl.rc('xtick', labelsize = 10)\n",
    "mpl.rc('ytick', labelsize = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cutting-limitation",
   "metadata": {},
   "source": [
    "## Get the data\n",
    "To start off, create a small function to automate fetching the data. This is useful for regularly fetching updates or when downloading the data on multiple machines is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "breathing-cabinet",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import urllib\n",
    "\n",
    "## TO DO: download data set and have it on personal github\n",
    "download_root = 'https://raw.githubusercontent.com/jaredvanblitterswyk/ml_handson_sklearn_keras_tf_v02/main/'\n",
    "data_path = os.path.join('datasets','cali_housing')\n",
    "data_url = download_root + 'datasets/housing.tgz'\n",
    "\n",
    "def fetch_data(data_url = data_url, data_path = data_path):\n",
    "    # make directory in current workspace\n",
    "    os.makedirs(data_path, exist_ok=True)\n",
    "    # define tar gz path to save locally\n",
    "    tgz_path = os.path.join(data_path, 'housing.tgz')\n",
    "    # download tar gz file\n",
    "    urllib.request.urlretrieve(data_url, tgz_path)\n",
    "    # open tar gz file and extract all as csv\n",
    "    with tarfile.open(tgz_path) as file:\n",
    "        file.extractall(path=data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "turkish-talent",
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equal-surrey",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
